---
layout: post
title: "ICCV Workshop Comprehensive Video Understanding in the Wild Summary - (1)"
date: 2019-10-27
tags: [AI]
comments: true
---
### Comprehensive Video Understanding in the Wild


한보형(SNU)

**Wealk Supervised Action Localization**
- Introduction
  - Definition
  - Motivation
  - Datasets
  - Video Representations
- Approaches
  - UntrimmedNet
  - ..

**Action Recognition**
- Classifying actions in videos
  - ex) making sandwich


**Action Localization**
- Classification + Localization

**Weakly Supervised Leaning**
- Motivation: Labeled datasets are often small or even unavailale
- HIgh annotation cost
  - Spatio-temporal regions
- Annotation Error Exists
- Goals
  - Reduce annotaiton costs
- Semi-supervised learning: few-shot learning
  - labels few data
  - augments labeled data 
- Learning with relaxed annotation

**Datasets**
- THUMOS
  - Dataset with untrimmed videos
  - Video-level annotations of 101 action classes
- AcivityNet 200 (ActivityNet 1.3)

Video Representations
- Two Stream CNNs
  - Spatial stream: CNN on a simgle image
  - Temporal stream: CNN on multi-frame optical flow
- C3D
- I3D
  - Two-stream inflated 3D ConvNet (I3D)
- Non-Local Neural Network
  - Self Attention Mechanism
- SlowFast Network
  - Slow pathway
  - Fast pathway


**UntrimmedNet**
- The first work for weakly supervised action localization
- An extension of a weakly supervised object detection technique
  - Seperate softmax on (proposal, class) matrix with respect to row and column
  - element wise product of the two softmax
- Sparse Temporal Pooling Network
  - Acrhitecture and loss function
  - Segment level features
  - T-CAMs (Temporal CAM)
- STPN with Background Modeling
  - Main Idea
  - Loss
    - $L_{fg} + \alpha L_{bg} + \beta L_{guide} + \gamma L_{cluster}$
- W-TALC
  - Main Idea
  - Loss
    - Multiple Instance Learning Loss (MILL)
      - All Segments from a video in each bag
      - Based on k-max-mean (mean of k-max; $s_i^j$) score of each class
    - Co-Activity SImilarity Loss (CASL)
      - Identifying the correlations between every pair of videos
- AutoLOC
  - Outer-Inner-Contrastive (OIC) loss
    - $A_o(\theta)-A_i(\theta)$
    - outer-inner
- Contrast-based Evaluation Network
  - Contrast-based Localization EvaluAtioN Network
    - Video level prediction: given by the fusion of
      - Snippet-level Classification PRedictions (SCP)
      - ..
- Temporal Structure Mining
  - Main Idea
    - Each action instance is modeled as a multi-phase process
    - Phase evolving within an action instance.
    - Phase filters are used to calculate the **confidence score** of the presense
  - Implementation
    - Each action is factorized into M phases.
    - 
**Performance**
- ~
- ~


**Recap**
- Identificaiton of candidate action regions
  - Attentions: W-TALC
  - CAM: AutoLOC
  - Both: STPN, CleanNet
- Inference unit
  - Proposal: UntrimmedNet

**Discussion**
- Limitation
  - Weak Representation capabiilty
    - representation learning for video is not mature yet.
      - Probably needs lot more data and beeter learning alogorithm for modeling spatio-temporal dependency
      - rely on flo information
    - No consensus to deal with variable lengths of videos
      - dividing into equal-sized segments
      - fixing the number of segments
  - Dataset Issues
    - Noisy supervision
    - Possible Solutions
    - Class overlaps between taget datasets
  - Architectures
    - It is not clear if architectural variations affect performance substantially
    - Training skills may be much more important than architecture design.
  - computational cost
    - hard to deal with large-scale datasets
    - Challenging to perform task-specific representation **fine-tuning**