---
layout: post
title: "텐서플로우 3rd Offline 밋업 요약"
date: 2019-10-20
tags: [AI]
comments: true
---


## Tensorflow 3rd Meetup

---

### TF in Production
   1. TFLite
      1. TFLite
         - TFLite Interpretation
      2. Incredible Performance
         - MobileNet
           - 더 좋아졌다.. bla...
         - Delegate
           - GPU ...
         - Optimization
           - Fixed Point vs Floating Point
         - Quantization
           - Training vs Post Training
           - Post Training 이 좋다?? 엥 왜 ..?
      3. EdgeTPU
         - 좋다 bla...
         - But Fixed Point Only 
         - Quantization 왜?
           - Energy Uage
           - 성능 ..? 
      4. TFLite
         - Converter, from.keras 존재
         - tf.lite.Optimize 존재
         - OptSet 존재
         - Converter의 convert Method 를 통해서, tfmodel 생성
         - 
   2. AutoScalable (SKT, AI Center)
      - AI Devops Cycle, AI Service Infra
      1. AI Serving Infra 구성 및 방법론
         - 대표적인 방법
            1. Tensorflow Serving
            2. Cloud PaaS
            3. **Flask 등을 이용한 범용 서빙 아키텍처 구성**
            4. **Full 사용 GPU 서버 혹은 VM 이용, Tensor-RT**
            5. Cloud Serverless + Cloud NoSQL
         - Scikit-learn Package는 어떻게 서빙할 것인가
           - PMML (Predictive Model Markup Lagnuage)
         - vCPU Docker vs GPU Docker
         - DL Server 고려해야할 것들
           - Pandas, Scikit-learn, ...
           - Online Serving 인 경우 Batch Inferece(S=1)인 경우
           - Python Multi Thread
           - 모델 압축
           - 처리 속도 vs 모델 사이즈
         - 왜 ResNet 만 가지고 비교? LSTM 고려하면 ...
           - GPU와 CPU 성능 크게 차이 안남
           - Ex) Bi-LSTM
             - Batch Size = 1
             - CPU가 더빨랐음 ..?
             - Sequential 1000번 반복 수행
               - 250 TPS -> log 같은 것은 전부다 비동기 처리
         - TensorRT를 이용하는 Restful API
           - Flask에서 TensorRT 엔진 Load
         - Python으로 해보자
           - Pandas 쓰지 않으면 성능 개 증가
           - Java 나 C#에 비해 가상함수 빈약
             - Functiontools 사용
             - Multi-process
           - MemoryView 활용
             - Data Memory 복사 방지
           - Microservice
           - 모든 것은 비동기
           - PMML + Python(-> Java)
           - 단순 전역 변수 사용은 X
             - WSGI -> ASGI
             - Hang 문제 생김
               - Low Level Debugging 필요

      2. Production AI Open Source Eco System
         1. 
         - Pandas UDF (Spark)
         - Horovod(.spark)
         - Petastorm
         - Horizon (DeepRL)
           - Pytorch + ONNX
         - TFX
         - mlflow
         - Rapids.ai
         - Clipper.ai
           - Clipper with DL/ML librart
         - ONNX
         1. Production AI DevOps (Infra)
            - DevOps
              - 지속적 통합과 배포
                - 도커
              - 마이크로서비스
                - 개발자의 영역
              - 코드형 인프라스트럭쳐
                - 이것을 위한 도구가 필요함
                - 테라폼 (클라우드 리소스를 코드 레벨에서 관리)
                  - 쿠버네티스 (자동 운영환경을 위한 kubernetes)
              - 마이크로 서비스를 위한 모니터링
              - 커뮤니케이션
                - 슬랙
            - Pod (컨테이너의 집합)
              - 기본 개념 단위
            - 선언적 설정으로 인프라 관리
              - CPU Percertange 와 같은 것 설정 가능
              - 서버 port 등
              - Hardware Computer(Node) 설정 
              - Node 밸런싱
            - 배포
              - Azure Devops 의 Pipeline 기능을 활용
              - Git (누가 했다. 무엇을 했다를 추적 및 관리 가능)
              - Azure 배포 넘버링 자동
              - 배포 기록 관리
                - 기록 기반 롤백
            - 환경별 변수관리
              - 변수관리를 안하도록 설계하는 것이 중요함
              - DB를 호출하게 해야함
            - 모델 서빙을 위한 패턴
              - One fat Image
              - Model puller sidecar
                - Volume 공유(Pod)
                - FIle과 WEb Server 따로 관리 가능
              - Attached volume
                - 클라우드 기능 사용하는 것임
                  - 쿠버네티스 기능사용하는 것

   3. Production 환경에서 연구허기(하이퍼커넥트, 하성주)
      - ML 관련 업무
      - 프덕션(서비스 중인/될 제품)과 연구(성공이 불확실한 기술 개발)의 이야기
        - 팀에서 수행한 Keyword SPotting
      - AI LAB 존재
      - Social Discovery + Real-time Video
      - AI Lab
        - 머신러닝 관련된 것 다함
        - 프로젝트 선정
        - 데이터 수집
        - 모델 개발 및 실험
        - 논문화
        - 기획 참여
        - 등
      - CPU만 써서 -> 아자르에 올라감
      - 모바일 환경에서 DL 집중
      - DEVIEW 2018
      - Workshop
        - 10개 학회
        - 3700편 논문
        - 유저 니즈/비즈니스 트렌드 기반 아이디어 브레인 스토밍
        - 1년 간 로드맵
      - Project Selection
        - 다양한 요소를 고려하여 프로젝트 선정
          - 실현 가능성
          - 임팩트
          - 기술적 중요도
          - 트렌드
        - 그 중 하나인 **키워드 검출**
      - Keyword Spotting
        - Hey Siri
        - Computer Vision -> NLP (도메인 확장)
        - Low haning fruit(Classification이 비교적 쉬움)
      - 수십 편/수백 편 리뷰
        - Literature Review
          - Google Spread Sheet (나라면 Notion 쓸 듯)
      - 그 후, BaseLine 정의
        - Baseline Selection
          - 합리적인 성능이 나오는지 (SOTA와 비교)
        - 구현 난이도 및 공식 코드 공개 여부
          - 재현이 까다로운 경우도 고려 -> 현업에서 코드를 Production 화
      - Data Set 정의
        - 논문들이 공통적으로 사용하는 데이터셋을 최대한 확보
        - Deployee를 캡처하고 있는 DataSet을 구해야 함
      - PoC
        - 새로운 아이디어 테스트
          - BaseLine 모델 개선
        - 달성하고 싶은 목표를 설정
          - 충분한 정확도 + 모바일 CPU 실시간
        - 단계적으로 방법 설정
          - 모델 크기
        - 중간 산출물
          - 중간 산출물이 Production 에서 활용할 수 있는 방안 고려
      - Process
        - 모델이 제품에 적용되기 위해 필요한 한바퀴 돌리기
          - 도메인 전처리
          - 병목 등 해결
      - Evaluation
        - 논문 Reporting
        - 학습 최적화 방벙에 따라 논문보다 더 잘나오는 경우가 있음
        - 프로덕션 환경에서는 다양한 메트릭을 보아야 할 수도 있음
          - 정확도 vs 시간 당 오탐률
          - FLOPS vs 실제 Latency
          - 모델의 확신에 따른 정밀도와 재현율
      - Research
        - 재현하면서, 논문구현하면서 아이디어 훔쳐오기
        - 다른 도메인에서 아이디어 가져오기
        - 팀원들과 토론
      - KWS Research Progress
        - Speech ResNet
          - 오리지날 ResNet과 다름
          - 약간 바꿔가니 성능 증가
        - 다만 속도가 충분히 빠르지 않아서 이를 가속할 방법을 고민
        - Audio
          - MFCC
          - 2D Conv
          - High Frequency + Low Frequency
            - 속도도 빠름
            - 캐시 친화적임
        - TC-ResNet
          - Temporal Convolution
          - 380배, Flops Time, hyperconnect/TC-Renset
        - 논문을 쓰다보면, 풀고 싶은 문제가 명확해짐
        - 실험
        - Ablation Test
          - 불필요한 컴포넌트
        - 어차피 숨기고 있어봐야 구글이 더 좋은 기술 내놓음
      - Ablation Test
        - 최종적인 모델에서 예전에는 의미가 있었으나 더 이상 의미 없는 부분이 있을 수 있음
      - Ablation Test로 제거
        - 프로덕션 환경에서 불필요한 것 제거
      - ㄱRetrospection
        - 기계학습 전문성 > 도메인 전문성
        - InterSpeech
      - Production + Research
        - 시도하고 실패할 수 있음을 인지
        - 팀에서는 리스크를 스스로 판단하고 움직일 수 있어야 함
        - 전문성이 잘 맞는 분야에서는 좋은 결과
      - 팀은 제품에 기여 해야 함
        - 팀에서 해당 고민을 꼭 해줘야 함
        - 기술의 활용에 대한 이야기를 해야함
      - **소프트웨어 개발력 + 기계학습 연구력**
      - Positive Game이 낫다
        - 회사와 팀 리더가 특히 고민해줘 야함
        - 팀원의 성장과 커리어 디벨롭먼트에 대한 고민
        - 회사도 팀원도 모두 윈윈하는 방법
      - 오너십
        - 이 기술이 회사에 쓸모가 있을까?
        - 연구를 위한 연구를 빛이 발할까?
        - 연구에서 막히는 경우 인내심을 발휘할 수 있는 이유
      - We Are Hiring!

   4. 당근마켓 추천 시스템 (전무익/ML Enginner)
      - 따뜻한 거래?
      - 지역기반 생활정보 플랫폼
      - 다양한 사람들을 위해 추천 준비
      - 첫 화면, 홈 피드
      - 피드 서비스
        - 피드가 메인인 서비스(유튜브,페이스북)
      - 첫화면에서 조진다
      - 피드 개인화
        - 다양한 사람들의 피드 보는 재미 강화
      - 첫 단계
        - 소규모 스타트업
        - 관련 개발 경험 없음
        - 최신 글의 중요성 고려
      - 추천 글을 피드 사이에 노출
      - 유튜브 추천 시스템
        - 사용자 정보 기반
        - 실시간 추천 처리
      - 추천 시스템 구조
      - 개인화 추천
        - 사용자 정보 ️️➡️ 추천 모델 ➡️ 다음 볼 글 예측
      - 추천 모델
        - two-stage
          - 후보 모델
          - 랭킹 모델
        - 먼저, 후보 모델만
      - 후보 모델
        - 최근 본글 id 50개, 사용자 지역, 다음 글 본 시간, Target (다음 볼 글)
        - User Vector 과 Article Vector
        - 좋아할 만한 200개 정도 찾기
      - 22%
        - MAP: 0.033
      - 실시간 처리
        - article vector를 학습하여 인덱스 구축
        - user vector와 모든 article vector 의 dot 연산
        - faiss 라이브러ㅣ 활용
      - Inference
        - CPU 0.01s
      - 추천 시스템 구축
        - 데이터 수집
        - 데이터 전처리
        - 디바이스, 서버 로그를 빅쿼리에 저장
      - 학습 Examples
      - BigQuery
        - aggregate
      - CSV 추출
      - 데이터 전처리
      - 학습에 필요한 데이터 전처리
        - 성능
        - 시간
        - 효율
      - 처리 작업
        - 양이 많아질수록 처리시간 선형적으로 증가
        - 병렬처리 -> TF Transform
        - Training-serving skew 방지
        - Python으로 데이터 파이프라인 작성
      - Training-serving skew
        - Training
        - Serving
      - 구글 클라우드 데이터 플로우
        - CSV 8GB
        - 14 Workes
        - 19분
      - TF Record 로 모델 학습
      - 클라우드 관리형 서비스 적합
        - Cloud AI Platform
      - Tensorflow Estimator로 모델 작성
      - Training Service로 학습 요청
      - Production 환경에서 빠르고 안정적으로 서비스
      - 새로운 글들에 대해서는 어떻게? -> 지속적으로 합격
        - 따라서 파이프라인 시스템
      - 파이프라인 시스템
        - 워크플로우 작업 실행
        - 실행 로그/결과 확인
        - 정해진 일정에 맞춰 실행
        - 직접 구현하기 보다는 오픈 소스 활용
        - Kuberflow
          - 컨테이너 기반
          - Python SDK
          - 웹 UI로 GKE에 간편 설치
      - 파이프라인 작성
        - KFP Python SDK 작성
        - 작업 정의 작성
          - 컨테이너 실행 명령
        - 작업 자동 연결
        - Compile
          - python - yarn
      - 파이프라인 배포
      - 파이프라인 배포 코드
        - 변경 후 배포 편의를 위해 코드화
      - Output Viewer
      - 추천 시스템 완성
        - A/B Test
        - 글 보기 6%+
        - 사용 시간 5%+
      - 당근마켓 머신러닝 팀
        - 딥러닝 기술을 서비스에 적용
        - 직접적으로 서비스 개선에 기여
        - 다양한 모델 활용
      - 채용
        - 딥러닝을 이해하고 활용 능력 뛰어난 개발자
        - 다양한 모델 연구자

---

### 라이트닝 톡
   1. 스타트업
      1. 마키나 블랙 (Legal-Tech, AI)
         - 법률 시장
         - 인공지능 변호사/ 인공지능 판사
         - 문서 -> NLP
         - 법률 문서를 번역
           - 영어도
           - 법률지식도
         - 비교를 구글이랑? 
         - 법률 문서
           - 일관성
           - 마키나블랙 -> 네이버 D2SF -> TR Ignite Finalist
         - 원하는 사람
           - ML Ops
           - NLP
           - Front-End
         - 어려운 문제에 도전, 극단전 진실, 합당한 보상
      2. Art Lab
         - AI & Robotics
         - Transformation
           - 변혁 = Team
         - 화장품
         - 기획 AI, 개발 AI
      3. 로민
         - Deep Fake 얼굴 검출
         - Scene Text Detection
           - API Service
         - 기존 문서 OCR
         - Slack, Notion, Office365, Github
      4. nota
         - Cloud based AI -> On device AI
         - Stand Alone AI
         - Machine Learning Enginner
      5.  SIA
         - 전태균
         - MeetUp
         - SIA
         - Google Developer Expert
         - AI Expertise (Research Activity)
         - 재밌는 경진대회
         - LabelEarth
         - Explainable AI
         - bit.ly/SIA2019JD
      6.  휴톰
          - 수술 데이터 -> 문제 해결
          - kinematics + 수술 영상
          - 위암 대장암 갑상선암
          - Confluence, Jira
      7.  Dacon
          - 문제와 시장
          - 분석해 줄 사람이 없음
          - 경진대회 (캐글 의뢰는 넘 비쌈)
          - 12건
          - 영상
          - 분석 
            - 비지니스
            - 데이터
          - 설계
            - 대회라는 형태로 설계
            - 대회의 결과물이 현업에 사용될 수 있도록
          - 운영
            - 치팅
            - 리포팅
            - 최대한 자동화
          - 코드리뷰 
          - 다양한 도메인 데이터
            - 성장 빠름
          - 비지니스 마인드
            - 데이터와 비지니스를 어떻게 연결시킬 것인가?
   2.  RP12
       - PR12 Season 1
       - PR12 Season 2
       - 2017월 4월 16일
       - 몇 편 -> 200번 째
       - AI Robotics
       - github.com/taeoh-kim/pr12
       - 431,766
       - Good: 3863
       - Bad: 238
       - Faster R-CNN
       - Season 3

---

### 이것 좀 알려주세요
   1.  Kafka(네이버)
       - 상품명 + 이미지
       - Kafka (분산 형 스트리밍 플랫폼 by LinkedIn)
       - 쇼핑몰에서 제공하는 카테고리
       - Tokenizing -> Integer -> Numpy Array
       - PIL Library
       - Image Preprocessing
         - 디스크 I/O가 없어야 함
         - 메모리에서 Decoding 
       - Consumer
       - Queue가 가득 -> Multi-processing
       - Batch로 만들어서 Classifier로 Inference
       - Batch에 따라서 성능 확인
       - Multi Process Class
         - Multiprocessing.Process 상속
         - 잘 종료하기 위해 stop()
         - run() 함수 작성
         - 결국 queue가 풀하면 대기
       - Process Start
         - Stop Signal 함수를 정의
       - Process Stop
         - Stop Signal 함수를 정의
       - Training Dataset
         - JPEG + CSV -> 한 파일
       - TFRecords가 그나마 적합
       - Spark-Tensorflow-Connector 설치해야 함
       - 기존 데이터 파이프라인보다 훨씬 편함
       - Image to DataFrame
         - Dataframe에는 url 정보가 있고
         - url to jpeg 함수 정의
       - tfrecords 로 저장할 때 파일 당 100-200MB가 적절
       - Load Data using tf.data
         - img_generator 구현 후, keras .fit_generator 구현 가능

   2.  GNN(카이스트 류성옥)
       - 분자 -> Graph
       - Inductive biases in neural network
         - Objective Function Minimization을 통해
         - Neural Network -> Universal Theorem
         - Representation Learning(Domain에 적합한)
           - 이미지 -> CNN
           - NLP -> RNN
           - 모델을 정의하는 순간 bias 가 정의됨
         - Image와 Sentence -> Grid 위에서 정의됨
         - Grid 위에서 정의되지 않으면 -> Graph NN
       - CNN
         - 기본개념 ~bla
       - GNN
         - Neighbor의 Feature를 통해 Weighted SUM
         - Adjacency Matrix A
       - Graph Attention Network
         - 관계를 더 잘 고려한, Attention Coefficient를 곱해서...
         - Attention 방법으로 
         - 물론 Self Attention도 가능
         - Inductive biases in the transformer
           - 위치에 따른 Encoding
           - Attention
       -  Message Passing Neural Network
          -  GRU를 사용가능??
          -  여기는 조꼼 모르겠네?
       -  Learning tasks with GAN
          -  Node Classification
          -  Edge-Level Prediction
             -  Connectivity Matrix
                -  User과 Item과 Relation 추론가능
                -  Relation Inference라고 일반적으로 부름
          -  Graph Molecule (property) Prediction
             -  Classificaiton, Regression
             -  Graph를 Vector 로 Embedding
             -  후 똑같이 하면 됨
          -  Graph Generative Model
             -  Graph Generation
             -  String -> Encoder -> Generation 이 일반적이었으나
             -  Graph Generative Model -> Realistic 한 Graph 를 더 잘 만들 수 있음
          -  Learning Physics Dynamics
             -  Graph 간의 관계가 존재한채로 움직일테고
             -  Graph가 어떻게 어떻게 관계가 있고
             -  Graph의 속도와 위치가 어떻게 될 것인가를 예측?
             -  Neural relation inference for interacting system
       -  github.com/SeongokRyu/Graph-neural-networks

   3.  나만의 코퍼스는 없다
       - SNU ECE/SNU
       - Speech Processing Lab
       - 다루는 것: 태스트에 관계 없이 일반적인 것
       - 안 다루는 것: 태스크마다 다를 수 있는 것
         - 구체적인 크롤링 기법
       - 왜 데이터를 만드나?
         - 이미 세상에 있는 데이터로느느 하기 힘든 어떤 일을 하기위해 
           - 언어별 특성을 무시할 수 없음
           - 언어화된 데이터는 다른 데이터의 semantic한 측면과 연관될 수 있음
           - 텍스트 언어는 이산적, 분절적 , 추상적
       - 자연어 코퍼스는
         - 존재하던 태스크에 해당 언어의 코퍼스가 없거나
         - 기존에 없던 태스크를 개별언어로 만들거나
       - 코퍼스 종류
         - 주석 없는 코퍼스 (말뭉치)
         - 주석 있는 (annotaed) 코퍼스
         - 병렬 코퍼스
       - 어노테이션의 종류
         - 통사에서 의미를 넘어 화용까지
         - speech, emotion, nli and figruative language
         - 사실 영역은 종종 경계가 흐려진다.
       - Main Reference: Natural Language Annotation
         - Model -> Annotation -> Evaluate -> Revise
         - 그냥 똑같음
       - 어노테이션은 혼자 하기 어렵다
         - 엄밀히는, 혼자해선 안된다???
           - 상의할 필요 없음
           - 하지만, 최소한 2명 이상
         - 주석자간 의견 일치도
           - Kappa
       - Reliabilty
         - 주석자들의 언어학 지식
           - 주석자의 언어학적인 훈련이 너무 많이 되어 있으면 실제 언어 사용의 경향성을 보장 못함?
         - 주석자들의 언어 배경
           - 최소 L2 정도(L1 모어)
         - 크라우드 소싱
       - Case Study 1
         - 호출어 없이 알아서 반응하는 음성 대화 서비스
           -  뭐를 해결?
              -  근거리/원거리 음성인식
              -  화자인식
              -  Noisy하고 비정형적인 것에 응답?
         - 기계가 어떤 문장에 반응해야 하는가?
           - 대화에서 문장의 경계는 어떻게 결정되어야 하는가?
         - Annotation Guide Line 작성
         - 마지막으로 ML/DL을 이용한 정량 측정
       - Case Study 2
         - Goal of Project
           - 동서울 발 유성행 소요시간
         - Class Imbalance 문제 발생
           - 데이터 증강
           - 최대한 스타일은 다르게 ...
         - Generated Corpus 검증 방법
         - Sentence Generation 과 Paraphrasing은 Anootation은 아니다
           - Consensus 를 얻는게 가장 적합한 방법
       - 데이터 수집
         - 구어체 텍스트 코퍼스
         - 문어체 텍스트 코퍼스
         - 음성 스크립트
         - 음성 전사 데이터
         - 음성 코퍼스
       - 데이터 정제
         - 정규표현식을 통한 정제
       - 데이터 레이블링
         - Human Labeling
         - 모델로 예측한 결과로 검토 후 다시 트레이닝
         - Automatic: 코퍼스 자체의 성질을 이용
           - ex1) IMDB나 NSMC에서 그러하듯 리뷰 점수를 이용한 데이터 레이블링